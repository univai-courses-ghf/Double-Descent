{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e24987361b6b48bc98b5e3a348cefa18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85bd260b937e4631924476706f50c87e",
              "IPY_MODEL_0d3385b873384b73a0394a9fb8f8c4a0",
              "IPY_MODEL_b954d212f81742e094db9235223b45cf"
            ],
            "layout": "IPY_MODEL_9c74ea8a23634ce29809fed3383a05a3"
          }
        },
        "85bd260b937e4631924476706f50c87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f4fbc6fb1414623b69cd313137298e3",
            "placeholder": "​",
            "style": "IPY_MODEL_a35bdb4c079d403b994f93295b070c03",
            "value": "100%"
          }
        },
        "0d3385b873384b73a0394a9fb8f8c4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc1f00919eec481ea8cc00ab9be13482",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dab0bc1d34b4d7dbd0a6922d4dc6050",
            "value": 170498071
          }
        },
        "b954d212f81742e094db9235223b45cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51886d5c79fc451f88a6d176bbe65726",
            "placeholder": "​",
            "style": "IPY_MODEL_5f17b6ce2cda4d17b108458ba247b923",
            "value": " 170498071/170498071 [00:05&lt;00:00, 32441857.68it/s]"
          }
        },
        "9c74ea8a23634ce29809fed3383a05a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f4fbc6fb1414623b69cd313137298e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a35bdb4c079d403b994f93295b070c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc1f00919eec481ea8cc00ab9be13482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dab0bc1d34b4d7dbd0a6922d4dc6050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51886d5c79fc451f88a6d176bbe65726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f17b6ce2cda4d17b108458ba247b923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/univai-courses-ghf/Double-Descent/blob/main/Double_Descent_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for GPU"
      ],
      "metadata": {
        "id": "oHFRv750_gzt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0euU-y_G7Zs6",
        "outputId": "873f11a7-2b46-485d-9bb3-a7aef7c6a636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 21 00:41:22 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "3ROthCIV_kMo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSg-K1VMsEbI"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging"
      ],
      "metadata": {
        "id": "YS42ZWsz_mWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = './' + 'results/'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "save_file = os.path.join(save_dir,'log_64.txt')"
      ],
      "metadata": {
        "id": "2RX7wLFtnWbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet"
      ],
      "metadata": {
        "id": "zNBBANHq_plY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtT6V94qsomx"
      },
      "source": [
        "class PreActBlock(nn.Module):\n",
        "    '''Pre-activation version of the BasicBlock.'''\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, **kwargs):\n",
        "        super(PreActBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "class PreActResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, init_channels=64):\n",
        "        super(PreActResNet, self).__init__()\n",
        "        self.in_planes = init_channels\n",
        "        c = init_channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, c, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.layer1 = self._make_layer(block, c, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 2*c, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 4*c, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 8*c, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(8*c*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        # eg: [2, 1, 1, ..., 1]. Only the first one downsamples.\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def make_resnet18k(k=64, num_classes=10) -> PreActResNet:\n",
        "    ''' Returns a ResNet18 with width parameter k. (k=64 is standard ResNet18)'''\n",
        "    return PreActResNet(PreActBlock, [2, 2, 2, 2], num_classes=num_classes, init_channels=k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Logging\n",
        "\n",
        "Modify the k parameter in make resnet18k() to experiment with different model widths"
      ],
      "metadata": {
        "id": "DCqFjYf-_uIR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTuCwqdXs9uH",
        "outputId": "5cb35991-c860-4043-e076-858ce8c57d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e24987361b6b48bc98b5e3a348cefa18",
            "85bd260b937e4631924476706f50c87e",
            "0d3385b873384b73a0394a9fb8f8c4a0",
            "b954d212f81742e094db9235223b45cf",
            "9c74ea8a23634ce29809fed3383a05a3",
            "6f4fbc6fb1414623b69cd313137298e3",
            "a35bdb4c079d403b994f93295b070c03",
            "cc1f00919eec481ea8cc00ab9be13482",
            "9dab0bc1d34b4d7dbd0a6922d4dc6050",
            "51886d5c79fc451f88a6d176bbe65726",
            "5f17b6ce2cda4d17b108458ba247b923"
          ]
        }
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "## 20% label noise to train set\n",
        "## Comment out below to turn off label noise\n",
        "num_samples = len(trainset.targets)\n",
        "rands = np.random.choice(num_samples, num_samples//5, replace=False)\n",
        "for rand in rands:\n",
        "  tmp = trainset.targets[rand]\n",
        "  trainset.targets[rand] = np.random.choice( list(range(0,tmp)) + list(range(tmp+1,10)) )\n",
        "## Comment out above to turn off label noise\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "net = make_resnet18k(k=64, num_classes=10)\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9) \n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    ## Flooding level\n",
        "    ## Comment in below to use flooding\n",
        "    # b = 0.1\n",
        "    ## Comment in above to use flooding\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        ## Comment in below to use flooding\n",
        "        # loss = (criterion(outputs, targets) - b).abs() + b\n",
        "        ## Comment in above to use flooding\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return train_loss/(batch_idx+1), 1-correct/total\n",
        "\n",
        "def test(epoch):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "        return test_loss/(batch_idx+1), 1-correct/total\n",
        "\n",
        "with open(save_file, 'a') as f:\n",
        "   f.write('Epoch,Train Loss,Train Error,Test Loss,Test Error\\n')\n",
        "\n",
        "for epoch in range(start_epoch+1, start_epoch+501):\n",
        "    train_loss, train_error = train(epoch)\n",
        "    test_loss, test_error = test(epoch)\n",
        "    print(f'Epoch: {epoch:03} | Train Loss: {train_loss:.04} | \\\n",
        "Train Error: {train_error:.04} | Test Loss: {test_loss:.04} | \\\n",
        "Test Error: {test_error:.04}')\n",
        "    with open(save_file, 'a') as f:\n",
        "      f.write(f'{epoch},{train_loss:.09},{train_error:.09},{test_loss:.09},{test_error:.09}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e24987361b6b48bc98b5e3a348cefa18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "Epoch: 001 | Train Loss: 1.878 | Train Error: 0.6403 | Test Loss: 1.304 | Test Error: 0.4618\n",
            "Epoch: 002 | Train Loss: 1.644 | Train Error: 0.5178 | Test Loss: 1.169 | Test Error: 0.3889\n",
            "Epoch: 003 | Train Loss: 1.536 | Train Error: 0.4665 | Test Loss: 1.069 | Test Error: 0.3479\n",
            "Epoch: 004 | Train Loss: 1.445 | Train Error: 0.4227 | Test Loss: 1.084 | Test Error: 0.3423\n",
            "Epoch: 005 | Train Loss: 1.386 | Train Error: 0.3962 | Test Loss: 0.8539 | Test Error: 0.257\n",
            "Epoch: 006 | Train Loss: 1.345 | Train Error: 0.3777 | Test Loss: 0.8156 | Test Error: 0.236\n",
            "Epoch: 007 | Train Loss: 1.303 | Train Error: 0.36 | Test Loss: 0.7961 | Test Error: 0.221\n",
            "Epoch: 008 | Train Loss: 1.273 | Train Error: 0.3482 | Test Loss: 0.7168 | Test Error: 0.201\n",
            "Epoch: 009 | Train Loss: 1.247 | Train Error: 0.3349 | Test Loss: 0.8081 | Test Error: 0.2343\n",
            "Epoch: 010 | Train Loss: 1.222 | Train Error: 0.3264 | Test Loss: 0.7609 | Test Error: 0.206\n",
            "Epoch: 011 | Train Loss: 1.202 | Train Error: 0.3185 | Test Loss: 0.6868 | Test Error: 0.1796\n",
            "Epoch: 012 | Train Loss: 1.183 | Train Error: 0.3121 | Test Loss: 0.7432 | Test Error: 0.2125\n",
            "Epoch: 013 | Train Loss: 1.165 | Train Error: 0.3049 | Test Loss: 0.7217 | Test Error: 0.1901\n",
            "Epoch: 014 | Train Loss: 1.151 | Train Error: 0.2988 | Test Loss: 0.7325 | Test Error: 0.2046\n",
            "Epoch: 015 | Train Loss: 1.134 | Train Error: 0.2949 | Test Loss: 0.6535 | Test Error: 0.1706\n",
            "Epoch: 016 | Train Loss: 1.117 | Train Error: 0.2881 | Test Loss: 0.6392 | Test Error: 0.1677\n",
            "Epoch: 017 | Train Loss: 1.1 | Train Error: 0.2828 | Test Loss: 0.6172 | Test Error: 0.1668\n",
            "Epoch: 018 | Train Loss: 1.087 | Train Error: 0.2786 | Test Loss: 0.6308 | Test Error: 0.1647\n",
            "Epoch: 019 | Train Loss: 1.07 | Train Error: 0.2732 | Test Loss: 0.5875 | Test Error: 0.1562\n",
            "Epoch: 020 | Train Loss: 1.06 | Train Error: 0.2713 | Test Loss: 0.6028 | Test Error: 0.1588\n",
            "Epoch: 021 | Train Loss: 1.043 | Train Error: 0.2636 | Test Loss: 0.6404 | Test Error: 0.1646\n",
            "Epoch: 022 | Train Loss: 1.029 | Train Error: 0.2627 | Test Loss: 0.6195 | Test Error: 0.1618\n",
            "Epoch: 023 | Train Loss: 1.014 | Train Error: 0.2579 | Test Loss: 0.6237 | Test Error: 0.1665\n",
            "Epoch: 024 | Train Loss: 1.001 | Train Error: 0.2557 | Test Loss: 0.6187 | Test Error: 0.155\n",
            "Epoch: 025 | Train Loss: 0.9828 | Train Error: 0.2496 | Test Loss: 0.5859 | Test Error: 0.1509\n",
            "Epoch: 026 | Train Loss: 0.9698 | Train Error: 0.247 | Test Loss: 0.6216 | Test Error: 0.1582\n",
            "Epoch: 027 | Train Loss: 0.955 | Train Error: 0.2436 | Test Loss: 0.6527 | Test Error: 0.1663\n",
            "Epoch: 028 | Train Loss: 0.9375 | Train Error: 0.2392 | Test Loss: 0.6357 | Test Error: 0.1615\n",
            "Epoch: 029 | Train Loss: 0.9226 | Train Error: 0.2367 | Test Loss: 0.607 | Test Error: 0.16\n",
            "Epoch: 030 | Train Loss: 0.9046 | Train Error: 0.2322 | Test Loss: 0.6549 | Test Error: 0.1736\n",
            "Epoch: 031 | Train Loss: 0.8871 | Train Error: 0.2295 | Test Loss: 0.664 | Test Error: 0.1707\n",
            "Epoch: 032 | Train Loss: 0.8706 | Train Error: 0.2271 | Test Loss: 0.6487 | Test Error: 0.1706\n",
            "Epoch: 033 | Train Loss: 0.8531 | Train Error: 0.2225 | Test Loss: 0.6749 | Test Error: 0.1733\n",
            "Epoch: 034 | Train Loss: 0.8385 | Train Error: 0.2207 | Test Loss: 0.6447 | Test Error: 0.169\n",
            "Epoch: 035 | Train Loss: 0.8171 | Train Error: 0.2159 | Test Loss: 0.6357 | Test Error: 0.1641\n",
            "Epoch: 036 | Train Loss: 0.7976 | Train Error: 0.2121 | Test Loss: 0.6723 | Test Error: 0.1696\n",
            "Epoch: 037 | Train Loss: 0.7797 | Train Error: 0.2083 | Test Loss: 0.6384 | Test Error: 0.1662\n",
            "Epoch: 038 | Train Loss: 0.7688 | Train Error: 0.2089 | Test Loss: 0.6446 | Test Error: 0.1695\n",
            "Epoch: 039 | Train Loss: 0.7402 | Train Error: 0.2014 | Test Loss: 0.7416 | Test Error: 0.1899\n",
            "Epoch: 040 | Train Loss: 0.7303 | Train Error: 0.2005 | Test Loss: 0.6551 | Test Error: 0.17\n",
            "Epoch: 041 | Train Loss: 0.7062 | Train Error: 0.1951 | Test Loss: 0.6994 | Test Error: 0.1796\n",
            "Epoch: 042 | Train Loss: 0.6864 | Train Error: 0.1905 | Test Loss: 0.7386 | Test Error: 0.1907\n",
            "Epoch: 043 | Train Loss: 0.6673 | Train Error: 0.1876 | Test Loss: 0.7375 | Test Error: 0.1824\n",
            "Epoch: 044 | Train Loss: 0.6476 | Train Error: 0.1833 | Test Loss: 0.815 | Test Error: 0.2081\n",
            "Epoch: 045 | Train Loss: 0.6308 | Train Error: 0.1803 | Test Loss: 0.783 | Test Error: 0.1958\n",
            "Epoch: 046 | Train Loss: 0.6135 | Train Error: 0.1773 | Test Loss: 0.8469 | Test Error: 0.212\n",
            "Epoch: 047 | Train Loss: 0.5946 | Train Error: 0.1726 | Test Loss: 0.8195 | Test Error: 0.2044\n",
            "Epoch: 048 | Train Loss: 0.5776 | Train Error: 0.1699 | Test Loss: 0.8662 | Test Error: 0.2143\n",
            "Epoch: 049 | Train Loss: 0.5573 | Train Error: 0.1653 | Test Loss: 0.8848 | Test Error: 0.2106\n",
            "Epoch: 050 | Train Loss: 0.5419 | Train Error: 0.1611 | Test Loss: 0.9209 | Test Error: 0.2339\n",
            "Epoch: 051 | Train Loss: 0.5205 | Train Error: 0.1576 | Test Loss: 0.9616 | Test Error: 0.2331\n",
            "Epoch: 052 | Train Loss: 0.5104 | Train Error: 0.1544 | Test Loss: 0.9203 | Test Error: 0.2179\n",
            "Epoch: 053 | Train Loss: 0.4915 | Train Error: 0.149 | Test Loss: 0.9636 | Test Error: 0.2401\n",
            "Epoch: 054 | Train Loss: 0.4763 | Train Error: 0.1471 | Test Loss: 0.9467 | Test Error: 0.2277\n",
            "Epoch: 055 | Train Loss: 0.4533 | Train Error: 0.1387 | Test Loss: 0.9655 | Test Error: 0.2228\n",
            "Epoch: 056 | Train Loss: 0.4388 | Train Error: 0.1352 | Test Loss: 1.095 | Test Error: 0.2594\n",
            "Epoch: 057 | Train Loss: 0.4378 | Train Error: 0.1364 | Test Loss: 0.9768 | Test Error: 0.2311\n",
            "Epoch: 058 | Train Loss: 0.4129 | Train Error: 0.1295 | Test Loss: 1.034 | Test Error: 0.255\n",
            "Epoch: 059 | Train Loss: 0.3978 | Train Error: 0.1259 | Test Loss: 1.055 | Test Error: 0.2591\n",
            "Epoch: 060 | Train Loss: 0.3902 | Train Error: 0.1259 | Test Loss: 1.064 | Test Error: 0.2601\n",
            "Epoch: 061 | Train Loss: 0.3731 | Train Error: 0.119 | Test Loss: 1.132 | Test Error: 0.2524\n",
            "Epoch: 062 | Train Loss: 0.3644 | Train Error: 0.1164 | Test Loss: 1.05 | Test Error: 0.24\n",
            "Epoch: 063 | Train Loss: 0.3472 | Train Error: 0.111 | Test Loss: 1.078 | Test Error: 0.2431\n",
            "Epoch: 064 | Train Loss: 0.3348 | Train Error: 0.1092 | Test Loss: 1.102 | Test Error: 0.24\n",
            "Epoch: 065 | Train Loss: 0.3346 | Train Error: 0.1086 | Test Loss: 1.082 | Test Error: 0.2382\n",
            "Epoch: 066 | Train Loss: 0.3134 | Train Error: 0.104 | Test Loss: 1.084 | Test Error: 0.2138\n",
            "Epoch: 067 | Train Loss: 0.3063 | Train Error: 0.09948 | Test Loss: 1.186 | Test Error: 0.2641\n",
            "Epoch: 068 | Train Loss: 0.2967 | Train Error: 0.09718 | Test Loss: 1.155 | Test Error: 0.2559\n",
            "Epoch: 069 | Train Loss: 0.2875 | Train Error: 0.09514 | Test Loss: 1.349 | Test Error: 0.2934\n",
            "Epoch: 070 | Train Loss: 0.2768 | Train Error: 0.09072 | Test Loss: 1.207 | Test Error: 0.2617\n",
            "Epoch: 071 | Train Loss: 0.2808 | Train Error: 0.09308 | Test Loss: 1.19 | Test Error: 0.2622\n",
            "Epoch: 072 | Train Loss: 0.2611 | Train Error: 0.08674 | Test Loss: 1.225 | Test Error: 0.2496\n",
            "Epoch: 073 | Train Loss: 0.2572 | Train Error: 0.08546 | Test Loss: 1.246 | Test Error: 0.2637\n",
            "Epoch: 074 | Train Loss: 0.2454 | Train Error: 0.08162 | Test Loss: 1.171 | Test Error: 0.223\n",
            "Epoch: 075 | Train Loss: 0.2437 | Train Error: 0.08108 | Test Loss: 1.217 | Test Error: 0.2424\n",
            "Epoch: 076 | Train Loss: 0.2346 | Train Error: 0.07764 | Test Loss: 1.229 | Test Error: 0.2635\n",
            "Epoch: 077 | Train Loss: 0.2305 | Train Error: 0.07626 | Test Loss: 1.124 | Test Error: 0.225\n",
            "Epoch: 078 | Train Loss: 0.2252 | Train Error: 0.07534 | Test Loss: 1.328 | Test Error: 0.2503\n",
            "Epoch: 079 | Train Loss: 0.2198 | Train Error: 0.07478 | Test Loss: 1.222 | Test Error: 0.244\n",
            "Epoch: 080 | Train Loss: 0.2132 | Train Error: 0.07062 | Test Loss: 1.171 | Test Error: 0.2284\n",
            "Epoch: 081 | Train Loss: 0.2073 | Train Error: 0.06932 | Test Loss: 1.346 | Test Error: 0.2483\n",
            "Epoch: 082 | Train Loss: 0.2076 | Train Error: 0.06868 | Test Loss: 1.347 | Test Error: 0.2665\n",
            "Epoch: 083 | Train Loss: 0.2021 | Train Error: 0.06796 | Test Loss: 1.361 | Test Error: 0.2805\n",
            "Epoch: 084 | Train Loss: 0.1911 | Train Error: 0.06294 | Test Loss: 1.334 | Test Error: 0.2552\n",
            "Epoch: 085 | Train Loss: 0.1911 | Train Error: 0.06426 | Test Loss: 1.335 | Test Error: 0.2651\n",
            "Epoch: 086 | Train Loss: 0.1924 | Train Error: 0.0644 | Test Loss: 1.221 | Test Error: 0.2473\n",
            "Epoch: 087 | Train Loss: 0.1811 | Train Error: 0.06078 | Test Loss: 1.207 | Test Error: 0.2231\n",
            "Epoch: 088 | Train Loss: 0.1694 | Train Error: 0.05568 | Test Loss: 1.342 | Test Error: 0.2525\n",
            "Epoch: 089 | Train Loss: 0.1774 | Train Error: 0.06046 | Test Loss: 1.287 | Test Error: 0.2244\n",
            "Epoch: 090 | Train Loss: 0.1731 | Train Error: 0.05928 | Test Loss: 1.366 | Test Error: 0.2533\n",
            "Epoch: 091 | Train Loss: 0.1677 | Train Error: 0.05628 | Test Loss: 1.325 | Test Error: 0.2548\n",
            "Epoch: 092 | Train Loss: 0.1614 | Train Error: 0.05428 | Test Loss: 1.333 | Test Error: 0.2523\n",
            "Epoch: 093 | Train Loss: 0.1569 | Train Error: 0.053 | Test Loss: 1.419 | Test Error: 0.2494\n",
            "Epoch: 094 | Train Loss: 0.1584 | Train Error: 0.05334 | Test Loss: 1.264 | Test Error: 0.2218\n",
            "Epoch: 095 | Train Loss: 0.1552 | Train Error: 0.05244 | Test Loss: 1.393 | Test Error: 0.2424\n",
            "Epoch: 096 | Train Loss: 0.1531 | Train Error: 0.05104 | Test Loss: 1.407 | Test Error: 0.2675\n",
            "Epoch: 097 | Train Loss: 0.1575 | Train Error: 0.0528 | Test Loss: 1.471 | Test Error: 0.2652\n",
            "Epoch: 098 | Train Loss: 0.152 | Train Error: 0.05056 | Test Loss: 1.405 | Test Error: 0.2743\n",
            "Epoch: 099 | Train Loss: 0.1403 | Train Error: 0.04698 | Test Loss: 1.362 | Test Error: 0.2418\n",
            "Epoch: 100 | Train Loss: 0.1434 | Train Error: 0.0486 | Test Loss: 1.278 | Test Error: 0.2228\n",
            "Epoch: 101 | Train Loss: 0.1421 | Train Error: 0.04694 | Test Loss: 1.268 | Test Error: 0.239\n",
            "Epoch: 102 | Train Loss: 0.1332 | Train Error: 0.04466 | Test Loss: 1.4 | Test Error: 0.2726\n",
            "Epoch: 103 | Train Loss: 0.1348 | Train Error: 0.04498 | Test Loss: 1.37 | Test Error: 0.2575\n",
            "Epoch: 104 | Train Loss: 0.1328 | Train Error: 0.04474 | Test Loss: 1.38 | Test Error: 0.2371\n",
            "Epoch: 105 | Train Loss: 0.1325 | Train Error: 0.04436 | Test Loss: 1.449 | Test Error: 0.2424\n",
            "Epoch: 106 | Train Loss: 0.134 | Train Error: 0.04414 | Test Loss: 1.431 | Test Error: 0.2672\n",
            "Epoch: 107 | Train Loss: 0.1336 | Train Error: 0.04568 | Test Loss: 1.298 | Test Error: 0.2217\n",
            "Epoch: 108 | Train Loss: 0.1324 | Train Error: 0.0442 | Test Loss: 1.461 | Test Error: 0.2511\n",
            "Epoch: 109 | Train Loss: 0.123 | Train Error: 0.04168 | Test Loss: 1.418 | Test Error: 0.251\n",
            "Epoch: 110 | Train Loss: 0.1219 | Train Error: 0.0411 | Test Loss: 1.409 | Test Error: 0.2407\n",
            "Epoch: 111 | Train Loss: 0.1208 | Train Error: 0.0403 | Test Loss: 1.354 | Test Error: 0.2177\n",
            "Epoch: 112 | Train Loss: 0.125 | Train Error: 0.0421 | Test Loss: 1.425 | Test Error: 0.2457\n",
            "Epoch: 113 | Train Loss: 0.1141 | Train Error: 0.0387 | Test Loss: 1.404 | Test Error: 0.2449\n",
            "Epoch: 114 | Train Loss: 0.1198 | Train Error: 0.04116 | Test Loss: 1.39 | Test Error: 0.229\n",
            "Epoch: 115 | Train Loss: 0.1184 | Train Error: 0.03978 | Test Loss: 1.418 | Test Error: 0.2411\n",
            "Epoch: 116 | Train Loss: 0.1061 | Train Error: 0.03656 | Test Loss: 1.399 | Test Error: 0.2421\n",
            "Epoch: 117 | Train Loss: 0.1139 | Train Error: 0.03916 | Test Loss: 1.392 | Test Error: 0.2325\n",
            "Epoch: 118 | Train Loss: 0.1199 | Train Error: 0.03922 | Test Loss: 1.467 | Test Error: 0.2548\n",
            "Epoch: 119 | Train Loss: 0.107 | Train Error: 0.03538 | Test Loss: 1.47 | Test Error: 0.2615\n",
            "Epoch: 120 | Train Loss: 0.1071 | Train Error: 0.03546 | Test Loss: 1.356 | Test Error: 0.2255\n",
            "Epoch: 121 | Train Loss: 0.1052 | Train Error: 0.03614 | Test Loss: 1.513 | Test Error: 0.2465\n",
            "Epoch: 122 | Train Loss: 0.1082 | Train Error: 0.03616 | Test Loss: 1.458 | Test Error: 0.2341\n",
            "Epoch: 123 | Train Loss: 0.1103 | Train Error: 0.03732 | Test Loss: 1.358 | Test Error: 0.228\n",
            "Epoch: 124 | Train Loss: 0.09992 | Train Error: 0.03362 | Test Loss: 1.421 | Test Error: 0.246\n",
            "Epoch: 125 | Train Loss: 0.1033 | Train Error: 0.03424 | Test Loss: 1.39 | Test Error: 0.2399\n",
            "Epoch: 126 | Train Loss: 0.1026 | Train Error: 0.03466 | Test Loss: 1.501 | Test Error: 0.2525\n",
            "Epoch: 127 | Train Loss: 0.1072 | Train Error: 0.03652 | Test Loss: 1.42 | Test Error: 0.2331\n",
            "Epoch: 128 | Train Loss: 0.09836 | Train Error: 0.03332 | Test Loss: 1.442 | Test Error: 0.2358\n",
            "Epoch: 129 | Train Loss: 0.09231 | Train Error: 0.0307 | Test Loss: 1.457 | Test Error: 0.2442\n",
            "Epoch: 130 | Train Loss: 0.1016 | Train Error: 0.03412 | Test Loss: 1.531 | Test Error: 0.2689\n",
            "Epoch: 131 | Train Loss: 0.09234 | Train Error: 0.03042 | Test Loss: 1.528 | Test Error: 0.2417\n",
            "Epoch: 132 | Train Loss: 0.09418 | Train Error: 0.03172 | Test Loss: 1.4 | Test Error: 0.225\n",
            "Epoch: 133 | Train Loss: 0.09974 | Train Error: 0.03338 | Test Loss: 1.495 | Test Error: 0.2468\n",
            "Epoch: 134 | Train Loss: 0.0923 | Train Error: 0.03046 | Test Loss: 1.428 | Test Error: 0.2437\n",
            "Epoch: 135 | Train Loss: 0.09046 | Train Error: 0.03012 | Test Loss: 1.404 | Test Error: 0.2245\n",
            "Epoch: 136 | Train Loss: 0.09325 | Train Error: 0.0307 | Test Loss: 1.461 | Test Error: 0.231\n",
            "Epoch: 137 | Train Loss: 0.09005 | Train Error: 0.03106 | Test Loss: 1.483 | Test Error: 0.2341\n",
            "Epoch: 138 | Train Loss: 0.09292 | Train Error: 0.0312 | Test Loss: 1.443 | Test Error: 0.2223\n",
            "Epoch: 139 | Train Loss: 0.08777 | Train Error: 0.02942 | Test Loss: 1.458 | Test Error: 0.2294\n",
            "Epoch: 140 | Train Loss: 0.09025 | Train Error: 0.02984 | Test Loss: 1.43 | Test Error: 0.2331\n",
            "Epoch: 141 | Train Loss: 0.08451 | Train Error: 0.02756 | Test Loss: 1.377 | Test Error: 0.2091\n",
            "Epoch: 142 | Train Loss: 0.08823 | Train Error: 0.02982 | Test Loss: 1.369 | Test Error: 0.213\n",
            "Epoch: 143 | Train Loss: 0.0834 | Train Error: 0.02806 | Test Loss: 1.464 | Test Error: 0.2259\n",
            "Epoch: 144 | Train Loss: 0.08935 | Train Error: 0.03056 | Test Loss: 1.369 | Test Error: 0.2246\n",
            "Epoch: 145 | Train Loss: 0.07646 | Train Error: 0.02532 | Test Loss: 1.503 | Test Error: 0.2624\n",
            "Epoch: 146 | Train Loss: 0.08196 | Train Error: 0.0273 | Test Loss: 1.395 | Test Error: 0.2266\n",
            "Epoch: 147 | Train Loss: 0.08222 | Train Error: 0.02728 | Test Loss: 1.398 | Test Error: 0.2221\n",
            "Epoch: 148 | Train Loss: 0.08341 | Train Error: 0.02768 | Test Loss: 1.454 | Test Error: 0.2315\n",
            "Epoch: 149 | Train Loss: 0.08427 | Train Error: 0.0278 | Test Loss: 1.452 | Test Error: 0.2343\n",
            "Epoch: 150 | Train Loss: 0.08475 | Train Error: 0.02884 | Test Loss: 1.355 | Test Error: 0.2052\n",
            "Epoch: 151 | Train Loss: 0.07482 | Train Error: 0.02536 | Test Loss: 1.442 | Test Error: 0.23\n",
            "Epoch: 152 | Train Loss: 0.08236 | Train Error: 0.02844 | Test Loss: 1.389 | Test Error: 0.2223\n",
            "Epoch: 153 | Train Loss: 0.07932 | Train Error: 0.0265 | Test Loss: 1.47 | Test Error: 0.239\n",
            "Epoch: 154 | Train Loss: 0.07876 | Train Error: 0.02588 | Test Loss: 1.429 | Test Error: 0.2108\n",
            "Epoch: 155 | Train Loss: 0.07976 | Train Error: 0.02674 | Test Loss: 1.422 | Test Error: 0.2359\n",
            "Epoch: 156 | Train Loss: 0.07659 | Train Error: 0.02522 | Test Loss: 1.436 | Test Error: 0.2299\n",
            "Epoch: 157 | Train Loss: 0.07024 | Train Error: 0.02294 | Test Loss: 1.464 | Test Error: 0.2173\n",
            "Epoch: 158 | Train Loss: 0.07907 | Train Error: 0.02632 | Test Loss: 1.492 | Test Error: 0.2396\n",
            "Epoch: 159 | Train Loss: 0.07492 | Train Error: 0.0244 | Test Loss: 1.467 | Test Error: 0.2215\n",
            "Epoch: 160 | Train Loss: 0.07172 | Train Error: 0.02372 | Test Loss: 1.482 | Test Error: 0.2269\n",
            "Epoch: 161 | Train Loss: 0.07371 | Train Error: 0.02414 | Test Loss: 1.454 | Test Error: 0.2328\n",
            "Epoch: 162 | Train Loss: 0.07339 | Train Error: 0.0247 | Test Loss: 1.475 | Test Error: 0.2269\n",
            "Epoch: 163 | Train Loss: 0.07008 | Train Error: 0.02294 | Test Loss: 1.516 | Test Error: 0.2444\n",
            "Epoch: 164 | Train Loss: 0.07237 | Train Error: 0.02412 | Test Loss: 1.461 | Test Error: 0.2151\n",
            "Epoch: 165 | Train Loss: 0.07383 | Train Error: 0.02452 | Test Loss: 1.417 | Test Error: 0.2223\n",
            "Epoch: 166 | Train Loss: 0.06778 | Train Error: 0.02318 | Test Loss: 1.546 | Test Error: 0.2315\n",
            "Epoch: 167 | Train Loss: 0.06455 | Train Error: 0.02184 | Test Loss: 1.551 | Test Error: 0.2094\n",
            "Epoch: 168 | Train Loss: 0.07577 | Train Error: 0.02566 | Test Loss: 1.482 | Test Error: 0.2252\n",
            "Epoch: 169 | Train Loss: 0.06642 | Train Error: 0.02272 | Test Loss: 1.557 | Test Error: 0.2267\n",
            "Epoch: 170 | Train Loss: 0.06524 | Train Error: 0.02102 | Test Loss: 1.453 | Test Error: 0.2033\n",
            "Epoch: 171 | Train Loss: 0.06581 | Train Error: 0.02228 | Test Loss: 1.466 | Test Error: 0.2174\n",
            "Epoch: 172 | Train Loss: 0.07029 | Train Error: 0.02402 | Test Loss: 1.521 | Test Error: 0.2357\n",
            "Epoch: 173 | Train Loss: 0.07694 | Train Error: 0.02482 | Test Loss: 1.388 | Test Error: 0.2074\n",
            "Epoch: 174 | Train Loss: 0.06075 | Train Error: 0.02026 | Test Loss: 1.495 | Test Error: 0.2274\n",
            "Epoch: 175 | Train Loss: 0.05989 | Train Error: 0.01978 | Test Loss: 1.475 | Test Error: 0.2083\n",
            "Epoch: 176 | Train Loss: 0.07521 | Train Error: 0.02494 | Test Loss: 1.418 | Test Error: 0.2096\n",
            "Epoch: 177 | Train Loss: 0.06617 | Train Error: 0.02198 | Test Loss: 1.457 | Test Error: 0.2086\n",
            "Epoch: 178 | Train Loss: 0.0596 | Train Error: 0.02004 | Test Loss: 1.468 | Test Error: 0.2197\n",
            "Epoch: 179 | Train Loss: 0.06452 | Train Error: 0.0214 | Test Loss: 1.589 | Test Error: 0.2383\n",
            "Epoch: 180 | Train Loss: 0.06519 | Train Error: 0.02142 | Test Loss: 1.522 | Test Error: 0.2234\n",
            "Epoch: 181 | Train Loss: 0.06562 | Train Error: 0.02088 | Test Loss: 1.449 | Test Error: 0.2155\n",
            "Epoch: 182 | Train Loss: 0.06499 | Train Error: 0.02172 | Test Loss: 1.483 | Test Error: 0.2277\n",
            "Epoch: 183 | Train Loss: 0.06149 | Train Error: 0.02116 | Test Loss: 1.446 | Test Error: 0.2144\n",
            "Epoch: 184 | Train Loss: 0.05766 | Train Error: 0.01934 | Test Loss: 1.497 | Test Error: 0.2248\n",
            "Epoch: 185 | Train Loss: 0.06225 | Train Error: 0.02042 | Test Loss: 1.502 | Test Error: 0.2265\n",
            "Epoch: 186 | Train Loss: 0.06353 | Train Error: 0.02058 | Test Loss: 1.495 | Test Error: 0.2227\n",
            "Epoch: 187 | Train Loss: 0.05813 | Train Error: 0.01972 | Test Loss: 1.484 | Test Error: 0.2287\n",
            "Epoch: 188 | Train Loss: 0.05548 | Train Error: 0.01866 | Test Loss: 1.503 | Test Error: 0.2277\n",
            "Epoch: 189 | Train Loss: 0.06288 | Train Error: 0.02056 | Test Loss: 1.381 | Test Error: 0.2015\n",
            "Epoch: 190 | Train Loss: 0.06065 | Train Error: 0.0205 | Test Loss: 1.442 | Test Error: 0.2279\n",
            "Epoch: 191 | Train Loss: 0.06041 | Train Error: 0.02036 | Test Loss: 1.492 | Test Error: 0.2061\n",
            "Epoch: 192 | Train Loss: 0.05773 | Train Error: 0.01984 | Test Loss: 1.543 | Test Error: 0.2345\n",
            "Epoch: 193 | Train Loss: 0.05378 | Train Error: 0.01812 | Test Loss: 1.541 | Test Error: 0.2368\n",
            "Epoch: 194 | Train Loss: 0.0619 | Train Error: 0.02072 | Test Loss: 1.5 | Test Error: 0.2105\n",
            "Epoch: 195 | Train Loss: 0.0571 | Train Error: 0.01946 | Test Loss: 1.475 | Test Error: 0.2061\n",
            "Epoch: 196 | Train Loss: 0.0581 | Train Error: 0.0195 | Test Loss: 1.483 | Test Error: 0.2081\n",
            "Epoch: 197 | Train Loss: 0.05965 | Train Error: 0.01972 | Test Loss: 1.398 | Test Error: 0.2058\n",
            "Epoch: 198 | Train Loss: 0.0567 | Train Error: 0.01868 | Test Loss: 1.429 | Test Error: 0.2143\n",
            "Epoch: 199 | Train Loss: 0.05177 | Train Error: 0.0173 | Test Loss: 1.445 | Test Error: 0.22\n",
            "Epoch: 200 | Train Loss: 0.05623 | Train Error: 0.01832 | Test Loss: 1.632 | Test Error: 0.2579\n",
            "Epoch: 201 | Train Loss: 0.05196 | Train Error: 0.01762 | Test Loss: 1.5 | Test Error: 0.2219\n",
            "Epoch: 202 | Train Loss: 0.0573 | Train Error: 0.01952 | Test Loss: 1.47 | Test Error: 0.215\n",
            "Epoch: 203 | Train Loss: 0.05704 | Train Error: 0.01902 | Test Loss: 1.509 | Test Error: 0.2278\n",
            "Epoch: 204 | Train Loss: 0.04968 | Train Error: 0.01648 | Test Loss: 1.509 | Test Error: 0.2146\n",
            "Epoch: 205 | Train Loss: 0.0498 | Train Error: 0.0169 | Test Loss: 1.494 | Test Error: 0.2236\n",
            "Epoch: 206 | Train Loss: 0.05411 | Train Error: 0.01786 | Test Loss: 1.524 | Test Error: 0.2321\n",
            "Epoch: 207 | Train Loss: 0.05977 | Train Error: 0.01982 | Test Loss: 1.491 | Test Error: 0.2147\n",
            "Epoch: 208 | Train Loss: 0.05242 | Train Error: 0.01714 | Test Loss: 1.444 | Test Error: 0.2101\n",
            "Epoch: 209 | Train Loss: 0.05582 | Train Error: 0.01914 | Test Loss: 1.521 | Test Error: 0.2382\n",
            "Epoch: 210 | Train Loss: 0.05146 | Train Error: 0.01642 | Test Loss: 1.531 | Test Error: 0.2196\n",
            "Epoch: 211 | Train Loss: 0.04946 | Train Error: 0.01676 | Test Loss: 1.565 | Test Error: 0.2271\n",
            "Epoch: 212 | Train Loss: 0.0533 | Train Error: 0.01782 | Test Loss: 1.499 | Test Error: 0.2211\n",
            "Epoch: 213 | Train Loss: 0.05704 | Train Error: 0.01842 | Test Loss: 1.559 | Test Error: 0.2268\n",
            "Epoch: 214 | Train Loss: 0.04973 | Train Error: 0.01614 | Test Loss: 1.622 | Test Error: 0.2508\n",
            "Epoch: 215 | Train Loss: 0.05227 | Train Error: 0.0172 | Test Loss: 1.633 | Test Error: 0.2389\n",
            "Epoch: 216 | Train Loss: 0.04804 | Train Error: 0.01564 | Test Loss: 1.606 | Test Error: 0.2228\n",
            "Epoch: 217 | Train Loss: 0.05252 | Train Error: 0.0177 | Test Loss: 1.46 | Test Error: 0.2061\n",
            "Epoch: 218 | Train Loss: 0.04717 | Train Error: 0.0158 | Test Loss: 1.504 | Test Error: 0.219\n",
            "Epoch: 219 | Train Loss: 0.05153 | Train Error: 0.01736 | Test Loss: 1.523 | Test Error: 0.2204\n",
            "Epoch: 220 | Train Loss: 0.05532 | Train Error: 0.01894 | Test Loss: 1.483 | Test Error: 0.2158\n",
            "Epoch: 221 | Train Loss: 0.05119 | Train Error: 0.01658 | Test Loss: 1.439 | Test Error: 0.2084\n",
            "Epoch: 222 | Train Loss: 0.04557 | Train Error: 0.01484 | Test Loss: 1.557 | Test Error: 0.2283\n",
            "Epoch: 223 | Train Loss: 0.05166 | Train Error: 0.01736 | Test Loss: 1.554 | Test Error: 0.2309\n",
            "Epoch: 224 | Train Loss: 0.04505 | Train Error: 0.01522 | Test Loss: 1.464 | Test Error: 0.1982\n",
            "Epoch: 225 | Train Loss: 0.0488 | Train Error: 0.0159 | Test Loss: 1.608 | Test Error: 0.2231\n",
            "Epoch: 226 | Train Loss: 0.04877 | Train Error: 0.01608 | Test Loss: 1.506 | Test Error: 0.2081\n",
            "Epoch: 227 | Train Loss: 0.04853 | Train Error: 0.01732 | Test Loss: 1.546 | Test Error: 0.2134\n",
            "Epoch: 228 | Train Loss: 0.04794 | Train Error: 0.0158 | Test Loss: 1.515 | Test Error: 0.2149\n",
            "Epoch: 229 | Train Loss: 0.04634 | Train Error: 0.01564 | Test Loss: 1.515 | Test Error: 0.2156\n",
            "Epoch: 230 | Train Loss: 0.04585 | Train Error: 0.01538 | Test Loss: 1.586 | Test Error: 0.2266\n",
            "Epoch: 231 | Train Loss: 0.04803 | Train Error: 0.01608 | Test Loss: 1.559 | Test Error: 0.2283\n",
            "Epoch: 232 | Train Loss: 0.04716 | Train Error: 0.01592 | Test Loss: 1.545 | Test Error: 0.2089\n",
            "Epoch: 233 | Train Loss: 0.04341 | Train Error: 0.01474 | Test Loss: 1.565 | Test Error: 0.2054\n",
            "Epoch: 234 | Train Loss: 0.0451 | Train Error: 0.01444 | Test Loss: 1.614 | Test Error: 0.2269\n",
            "Epoch: 235 | Train Loss: 0.04277 | Train Error: 0.0142 | Test Loss: 1.561 | Test Error: 0.2272\n",
            "Epoch: 236 | Train Loss: 0.04635 | Train Error: 0.01538 | Test Loss: 1.64 | Test Error: 0.2299\n",
            "Epoch: 237 | Train Loss: 0.04948 | Train Error: 0.01616 | Test Loss: 1.648 | Test Error: 0.2313\n",
            "Epoch: 238 | Train Loss: 0.04348 | Train Error: 0.01442 | Test Loss: 1.467 | Test Error: 0.202\n",
            "Epoch: 239 | Train Loss: 0.0445 | Train Error: 0.01494 | Test Loss: 1.613 | Test Error: 0.2204\n",
            "Epoch: 240 | Train Loss: 0.04466 | Train Error: 0.0145 | Test Loss: 1.666 | Test Error: 0.2416\n",
            "Epoch: 241 | Train Loss: 0.04659 | Train Error: 0.01524 | Test Loss: 1.656 | Test Error: 0.2224\n",
            "Epoch: 242 | Train Loss: 0.04683 | Train Error: 0.01508 | Test Loss: 1.59 | Test Error: 0.2316\n",
            "Epoch: 243 | Train Loss: 0.04433 | Train Error: 0.01394 | Test Loss: 1.478 | Test Error: 0.2173\n",
            "Epoch: 244 | Train Loss: 0.04555 | Train Error: 0.01506 | Test Loss: 1.613 | Test Error: 0.236\n",
            "Epoch: 245 | Train Loss: 0.04608 | Train Error: 0.01498 | Test Loss: 1.482 | Test Error: 0.2176\n",
            "Epoch: 246 | Train Loss: 0.04373 | Train Error: 0.01472 | Test Loss: 1.512 | Test Error: 0.2227\n",
            "Epoch: 247 | Train Loss: 0.0414 | Train Error: 0.01384 | Test Loss: 1.546 | Test Error: 0.2143\n",
            "Epoch: 248 | Train Loss: 0.04452 | Train Error: 0.01476 | Test Loss: 1.567 | Test Error: 0.2253\n",
            "Epoch: 249 | Train Loss: 0.03952 | Train Error: 0.01352 | Test Loss: 1.582 | Test Error: 0.2265\n",
            "Epoch: 250 | Train Loss: 0.04006 | Train Error: 0.01384 | Test Loss: 1.501 | Test Error: 0.2049\n",
            "Epoch: 251 | Train Loss: 0.04422 | Train Error: 0.01502 | Test Loss: 1.653 | Test Error: 0.2283\n",
            "Epoch: 252 | Train Loss: 0.04339 | Train Error: 0.01462 | Test Loss: 1.613 | Test Error: 0.2181\n",
            "Epoch: 253 | Train Loss: 0.04603 | Train Error: 0.01576 | Test Loss: 1.619 | Test Error: 0.2419\n",
            "Epoch: 254 | Train Loss: 0.03758 | Train Error: 0.01254 | Test Loss: 1.584 | Test Error: 0.2098\n",
            "Epoch: 255 | Train Loss: 0.03804 | Train Error: 0.01276 | Test Loss: 1.615 | Test Error: 0.2319\n",
            "Epoch: 256 | Train Loss: 0.04428 | Train Error: 0.01506 | Test Loss: 1.522 | Test Error: 0.1993\n",
            "Epoch: 257 | Train Loss: 0.04125 | Train Error: 0.01392 | Test Loss: 1.564 | Test Error: 0.2135\n",
            "Epoch: 258 | Train Loss: 0.04434 | Train Error: 0.01506 | Test Loss: 1.623 | Test Error: 0.2145\n",
            "Epoch: 259 | Train Loss: 0.04024 | Train Error: 0.01272 | Test Loss: 1.55 | Test Error: 0.2132\n",
            "Epoch: 260 | Train Loss: 0.04219 | Train Error: 0.01322 | Test Loss: 1.602 | Test Error: 0.2278\n",
            "Epoch: 261 | Train Loss: 0.04175 | Train Error: 0.01362 | Test Loss: 1.621 | Test Error: 0.2296\n",
            "Epoch: 262 | Train Loss: 0.03868 | Train Error: 0.01306 | Test Loss: 1.646 | Test Error: 0.2359\n",
            "Epoch: 263 | Train Loss: 0.03619 | Train Error: 0.01306 | Test Loss: 1.587 | Test Error: 0.2154\n",
            "Epoch: 264 | Train Loss: 0.03926 | Train Error: 0.01298 | Test Loss: 1.606 | Test Error: 0.2193\n",
            "Epoch: 265 | Train Loss: 0.03971 | Train Error: 0.01314 | Test Loss: 1.614 | Test Error: 0.2139\n",
            "Epoch: 266 | Train Loss: 0.04137 | Train Error: 0.01356 | Test Loss: 1.611 | Test Error: 0.218\n",
            "Epoch: 267 | Train Loss: 0.03802 | Train Error: 0.01228 | Test Loss: 1.637 | Test Error: 0.2302\n",
            "Epoch: 268 | Train Loss: 0.03803 | Train Error: 0.01304 | Test Loss: 1.615 | Test Error: 0.2119\n",
            "Epoch: 269 | Train Loss: 0.03859 | Train Error: 0.01254 | Test Loss: 1.666 | Test Error: 0.2311\n",
            "Epoch: 270 | Train Loss: 0.0378 | Train Error: 0.0126 | Test Loss: 1.568 | Test Error: 0.2128\n",
            "Epoch: 271 | Train Loss: 0.04128 | Train Error: 0.01394 | Test Loss: 1.673 | Test Error: 0.2215\n",
            "Epoch: 272 | Train Loss: 0.0388 | Train Error: 0.0123 | Test Loss: 1.583 | Test Error: 0.2164\n",
            "Epoch: 273 | Train Loss: 0.03603 | Train Error: 0.01208 | Test Loss: 1.582 | Test Error: 0.2102\n",
            "Epoch: 274 | Train Loss: 0.03677 | Train Error: 0.0121 | Test Loss: 1.578 | Test Error: 0.2156\n",
            "Epoch: 275 | Train Loss: 0.03947 | Train Error: 0.0129 | Test Loss: 1.502 | Test Error: 0.206\n",
            "Epoch: 276 | Train Loss: 0.03841 | Train Error: 0.01252 | Test Loss: 1.692 | Test Error: 0.2304\n",
            "Epoch: 277 | Train Loss: 0.0379 | Train Error: 0.01258 | Test Loss: 1.593 | Test Error: 0.2088\n",
            "Epoch: 278 | Train Loss: 0.03456 | Train Error: 0.01156 | Test Loss: 1.568 | Test Error: 0.2161\n",
            "Epoch: 279 | Train Loss: 0.03472 | Train Error: 0.01136 | Test Loss: 1.551 | Test Error: 0.2143\n",
            "Epoch: 280 | Train Loss: 0.03508 | Train Error: 0.01184 | Test Loss: 1.65 | Test Error: 0.2154\n",
            "Epoch: 281 | Train Loss: 0.04126 | Train Error: 0.01318 | Test Loss: 1.563 | Test Error: 0.2114\n",
            "Epoch: 282 | Train Loss: 0.04428 | Train Error: 0.01416 | Test Loss: 1.571 | Test Error: 0.2282\n",
            "Epoch: 283 | Train Loss: 0.03312 | Train Error: 0.01106 | Test Loss: 1.696 | Test Error: 0.2347\n",
            "Epoch: 284 | Train Loss: 0.03891 | Train Error: 0.01226 | Test Loss: 1.585 | Test Error: 0.2101\n",
            "Epoch: 285 | Train Loss: 0.03617 | Train Error: 0.01214 | Test Loss: 1.622 | Test Error: 0.2248\n",
            "Epoch: 286 | Train Loss: 0.03319 | Train Error: 0.0112 | Test Loss: 1.598 | Test Error: 0.2115\n",
            "Epoch: 287 | Train Loss: 0.03521 | Train Error: 0.0111 | Test Loss: 1.544 | Test Error: 0.1984\n",
            "Epoch: 288 | Train Loss: 0.03448 | Train Error: 0.01114 | Test Loss: 1.676 | Test Error: 0.2231\n",
            "Epoch: 289 | Train Loss: 0.03989 | Train Error: 0.01376 | Test Loss: 1.692 | Test Error: 0.2347\n",
            "Epoch: 290 | Train Loss: 0.0411 | Train Error: 0.01362 | Test Loss: 1.586 | Test Error: 0.2204\n",
            "Epoch: 291 | Train Loss: 0.03329 | Train Error: 0.0108 | Test Loss: 1.505 | Test Error: 0.2049\n",
            "Epoch: 292 | Train Loss: 0.02955 | Train Error: 0.00916 | Test Loss: 1.606 | Test Error: 0.2109\n",
            "Epoch: 293 | Train Loss: 0.03729 | Train Error: 0.01168 | Test Loss: 1.6 | Test Error: 0.2192\n",
            "Epoch: 294 | Train Loss: 0.03462 | Train Error: 0.0115 | Test Loss: 1.578 | Test Error: 0.2178\n",
            "Epoch: 295 | Train Loss: 0.03362 | Train Error: 0.01104 | Test Loss: 1.563 | Test Error: 0.2206\n",
            "Epoch: 296 | Train Loss: 0.03459 | Train Error: 0.01106 | Test Loss: 1.587 | Test Error: 0.201\n",
            "Epoch: 297 | Train Loss: 0.03505 | Train Error: 0.01136 | Test Loss: 1.769 | Test Error: 0.2374\n",
            "Epoch: 298 | Train Loss: 0.03573 | Train Error: 0.01186 | Test Loss: 1.655 | Test Error: 0.2179\n",
            "Epoch: 299 | Train Loss: 0.03568 | Train Error: 0.012 | Test Loss: 1.677 | Test Error: 0.218\n",
            "Epoch: 300 | Train Loss: 0.03459 | Train Error: 0.01186 | Test Loss: 1.627 | Test Error: 0.2074\n",
            "Epoch: 301 | Train Loss: 0.03414 | Train Error: 0.01158 | Test Loss: 1.565 | Test Error: 0.2142\n",
            "Epoch: 302 | Train Loss: 0.03441 | Train Error: 0.01176 | Test Loss: 1.638 | Test Error: 0.226\n",
            "Epoch: 303 | Train Loss: 0.03087 | Train Error: 0.01054 | Test Loss: 1.65 | Test Error: 0.2099\n",
            "Epoch: 304 | Train Loss: 0.0339 | Train Error: 0.01166 | Test Loss: 1.646 | Test Error: 0.2145\n",
            "Epoch: 305 | Train Loss: 0.03251 | Train Error: 0.01126 | Test Loss: 1.572 | Test Error: 0.2053\n",
            "Epoch: 306 | Train Loss: 0.03485 | Train Error: 0.0114 | Test Loss: 1.687 | Test Error: 0.2335\n",
            "Epoch: 307 | Train Loss: 0.03372 | Train Error: 0.01082 | Test Loss: 1.674 | Test Error: 0.2257\n",
            "Epoch: 308 | Train Loss: 0.03526 | Train Error: 0.01196 | Test Loss: 1.566 | Test Error: 0.203\n",
            "Epoch: 309 | Train Loss: 0.03351 | Train Error: 0.0109 | Test Loss: 1.653 | Test Error: 0.2201\n",
            "Epoch: 310 | Train Loss: 0.03234 | Train Error: 0.01078 | Test Loss: 1.689 | Test Error: 0.2152\n",
            "Epoch: 311 | Train Loss: 0.02922 | Train Error: 0.00944 | Test Loss: 1.689 | Test Error: 0.2385\n",
            "Epoch: 312 | Train Loss: 0.03228 | Train Error: 0.01072 | Test Loss: 1.702 | Test Error: 0.2265\n",
            "Epoch: 313 | Train Loss: 0.03406 | Train Error: 0.01146 | Test Loss: 1.691 | Test Error: 0.225\n",
            "Epoch: 314 | Train Loss: 0.0365 | Train Error: 0.01194 | Test Loss: 1.603 | Test Error: 0.2116\n",
            "Epoch: 315 | Train Loss: 0.03348 | Train Error: 0.01152 | Test Loss: 1.585 | Test Error: 0.2123\n",
            "Epoch: 316 | Train Loss: 0.02826 | Train Error: 0.00944 | Test Loss: 1.559 | Test Error: 0.2036\n",
            "Epoch: 317 | Train Loss: 0.03189 | Train Error: 0.01006 | Test Loss: 1.662 | Test Error: 0.2236\n",
            "Epoch: 318 | Train Loss: 0.02825 | Train Error: 0.00978 | Test Loss: 1.608 | Test Error: 0.2134\n",
            "Epoch: 319 | Train Loss: 0.03279 | Train Error: 0.01098 | Test Loss: 1.654 | Test Error: 0.2266\n",
            "Epoch: 320 | Train Loss: 0.03348 | Train Error: 0.01156 | Test Loss: 1.607 | Test Error: 0.2181\n",
            "Epoch: 321 | Train Loss: 0.03136 | Train Error: 0.01064 | Test Loss: 1.687 | Test Error: 0.2253\n",
            "Epoch: 322 | Train Loss: 0.03435 | Train Error: 0.01124 | Test Loss: 1.578 | Test Error: 0.2118\n",
            "Epoch: 323 | Train Loss: 0.02948 | Train Error: 0.00948 | Test Loss: 1.639 | Test Error: 0.2095\n",
            "Epoch: 324 | Train Loss: 0.02973 | Train Error: 0.00966 | Test Loss: 1.585 | Test Error: 0.2156\n",
            "Epoch: 325 | Train Loss: 0.02764 | Train Error: 0.00896 | Test Loss: 1.594 | Test Error: 0.2085\n",
            "Epoch: 326 | Train Loss: 0.02813 | Train Error: 0.00916 | Test Loss: 1.678 | Test Error: 0.2199\n",
            "Epoch: 327 | Train Loss: 0.03496 | Train Error: 0.01124 | Test Loss: 1.613 | Test Error: 0.2168\n",
            "Epoch: 328 | Train Loss: 0.02749 | Train Error: 0.0093 | Test Loss: 1.642 | Test Error: 0.2245\n",
            "Epoch: 329 | Train Loss: 0.03317 | Train Error: 0.01122 | Test Loss: 1.63 | Test Error: 0.2078\n",
            "Epoch: 330 | Train Loss: 0.02712 | Train Error: 0.00936 | Test Loss: 1.612 | Test Error: 0.2101\n",
            "Epoch: 331 | Train Loss: 0.03033 | Train Error: 0.01136 | Test Loss: 1.711 | Test Error: 0.2149\n",
            "Epoch: 332 | Train Loss: 0.02989 | Train Error: 0.0098 | Test Loss: 1.582 | Test Error: 0.2058\n",
            "Epoch: 333 | Train Loss: 0.03324 | Train Error: 0.0107 | Test Loss: 1.633 | Test Error: 0.2102\n",
            "Epoch: 334 | Train Loss: 0.03416 | Train Error: 0.01154 | Test Loss: 1.685 | Test Error: 0.2174\n",
            "Epoch: 335 | Train Loss: 0.02925 | Train Error: 0.00936 | Test Loss: 1.593 | Test Error: 0.2132\n",
            "Epoch: 336 | Train Loss: 0.02651 | Train Error: 0.00832 | Test Loss: 1.682 | Test Error: 0.2073\n",
            "Epoch: 337 | Train Loss: 0.02928 | Train Error: 0.00988 | Test Loss: 1.625 | Test Error: 0.216\n",
            "Epoch: 338 | Train Loss: 0.02603 | Train Error: 0.0086 | Test Loss: 1.709 | Test Error: 0.2134\n",
            "Epoch: 339 | Train Loss: 0.02856 | Train Error: 0.0096 | Test Loss: 1.708 | Test Error: 0.2187\n",
            "Epoch: 340 | Train Loss: 0.0331 | Train Error: 0.0109 | Test Loss: 1.55 | Test Error: 0.1967\n",
            "Epoch: 341 | Train Loss: 0.03091 | Train Error: 0.01034 | Test Loss: 1.591 | Test Error: 0.2087\n",
            "Epoch: 342 | Train Loss: 0.02639 | Train Error: 0.00848 | Test Loss: 1.67 | Test Error: 0.218\n",
            "Epoch: 343 | Train Loss: 0.02798 | Train Error: 0.00904 | Test Loss: 1.602 | Test Error: 0.1941\n",
            "Epoch: 344 | Train Loss: 0.03029 | Train Error: 0.00978 | Test Loss: 1.601 | Test Error: 0.2111\n",
            "Epoch: 345 | Train Loss: 0.02911 | Train Error: 0.00968 | Test Loss: 1.599 | Test Error: 0.2059\n",
            "Epoch: 346 | Train Loss: 0.02871 | Train Error: 0.0092 | Test Loss: 1.687 | Test Error: 0.2153\n",
            "Epoch: 347 | Train Loss: 0.02683 | Train Error: 0.00898 | Test Loss: 1.597 | Test Error: 0.2034\n",
            "Epoch: 348 | Train Loss: 0.0311 | Train Error: 0.01018 | Test Loss: 1.632 | Test Error: 0.2063\n",
            "Epoch: 349 | Train Loss: 0.02696 | Train Error: 0.00874 | Test Loss: 1.635 | Test Error: 0.2157\n",
            "Epoch: 350 | Train Loss: 0.02607 | Train Error: 0.00864 | Test Loss: 1.6 | Test Error: 0.2104\n",
            "Epoch: 351 | Train Loss: 0.02941 | Train Error: 0.00972 | Test Loss: 1.692 | Test Error: 0.214\n",
            "Epoch: 352 | Train Loss: 0.02982 | Train Error: 0.00948 | Test Loss: 1.548 | Test Error: 0.2037\n",
            "Epoch: 353 | Train Loss: 0.02687 | Train Error: 0.0089 | Test Loss: 1.603 | Test Error: 0.2076\n",
            "Epoch: 354 | Train Loss: 0.02863 | Train Error: 0.0097 | Test Loss: 1.628 | Test Error: 0.2045\n",
            "Epoch: 355 | Train Loss: 0.02742 | Train Error: 0.00942 | Test Loss: 1.567 | Test Error: 0.1896\n",
            "Epoch: 356 | Train Loss: 0.02809 | Train Error: 0.00884 | Test Loss: 1.656 | Test Error: 0.2065\n",
            "Epoch: 357 | Train Loss: 0.02889 | Train Error: 0.00934 | Test Loss: 1.634 | Test Error: 0.2088\n",
            "Epoch: 358 | Train Loss: 0.03071 | Train Error: 0.01026 | Test Loss: 1.771 | Test Error: 0.2431\n",
            "Epoch: 359 | Train Loss: 0.026 | Train Error: 0.00848 | Test Loss: 1.639 | Test Error: 0.2086\n",
            "Epoch: 360 | Train Loss: 0.02973 | Train Error: 0.00936 | Test Loss: 1.729 | Test Error: 0.2162\n",
            "Epoch: 361 | Train Loss: 0.03032 | Train Error: 0.01022 | Test Loss: 1.658 | Test Error: 0.2128\n",
            "Epoch: 362 | Train Loss: 0.0283 | Train Error: 0.00944 | Test Loss: 1.645 | Test Error: 0.2085\n",
            "Epoch: 363 | Train Loss: 0.02646 | Train Error: 0.00892 | Test Loss: 1.602 | Test Error: 0.2113\n",
            "Epoch: 364 | Train Loss: 0.02701 | Train Error: 0.00852 | Test Loss: 1.542 | Test Error: 0.2016\n",
            "Epoch: 365 | Train Loss: 0.02414 | Train Error: 0.00792 | Test Loss: 1.583 | Test Error: 0.2038\n",
            "Epoch: 366 | Train Loss: 0.02759 | Train Error: 0.00942 | Test Loss: 1.651 | Test Error: 0.2088\n",
            "Epoch: 367 | Train Loss: 0.02774 | Train Error: 0.00886 | Test Loss: 1.607 | Test Error: 0.2146\n",
            "Epoch: 368 | Train Loss: 0.026 | Train Error: 0.00854 | Test Loss: 1.627 | Test Error: 0.2175\n",
            "Epoch: 369 | Train Loss: 0.02584 | Train Error: 0.00858 | Test Loss: 1.651 | Test Error: 0.2098\n",
            "Epoch: 370 | Train Loss: 0.02243 | Train Error: 0.0075 | Test Loss: 1.682 | Test Error: 0.218\n",
            "Epoch: 371 | Train Loss: 0.03115 | Train Error: 0.00998 | Test Loss: 1.766 | Test Error: 0.219\n",
            "Epoch: 372 | Train Loss: 0.02989 | Train Error: 0.01006 | Test Loss: 1.642 | Test Error: 0.2125\n",
            "Epoch: 373 | Train Loss: 0.02525 | Train Error: 0.0087 | Test Loss: 1.674 | Test Error: 0.2184\n",
            "Epoch: 374 | Train Loss: 0.02623 | Train Error: 0.00872 | Test Loss: 1.617 | Test Error: 0.212\n",
            "Epoch: 375 | Train Loss: 0.02766 | Train Error: 0.00876 | Test Loss: 1.653 | Test Error: 0.2131\n",
            "Epoch: 376 | Train Loss: 0.02849 | Train Error: 0.00922 | Test Loss: 1.672 | Test Error: 0.199\n",
            "Epoch: 377 | Train Loss: 0.02691 | Train Error: 0.00844 | Test Loss: 1.565 | Test Error: 0.1985\n",
            "Epoch: 378 | Train Loss: 0.0227 | Train Error: 0.00726 | Test Loss: 1.638 | Test Error: 0.2136\n",
            "Epoch: 379 | Train Loss: 0.02114 | Train Error: 0.00702 | Test Loss: 1.645 | Test Error: 0.2045\n",
            "Epoch: 380 | Train Loss: 0.02944 | Train Error: 0.01034 | Test Loss: 1.776 | Test Error: 0.2164\n",
            "Epoch: 381 | Train Loss: 0.02683 | Train Error: 0.00902 | Test Loss: 1.689 | Test Error: 0.2053\n",
            "Epoch: 382 | Train Loss: 0.02435 | Train Error: 0.00854 | Test Loss: 1.765 | Test Error: 0.2264\n",
            "Epoch: 383 | Train Loss: 0.02393 | Train Error: 0.00784 | Test Loss: 1.721 | Test Error: 0.2188\n",
            "Epoch: 384 | Train Loss: 0.02333 | Train Error: 0.00754 | Test Loss: 1.717 | Test Error: 0.2131\n",
            "Epoch: 385 | Train Loss: 0.0301 | Train Error: 0.01016 | Test Loss: 1.812 | Test Error: 0.2271\n",
            "Epoch: 386 | Train Loss: 0.02681 | Train Error: 0.0089 | Test Loss: 1.646 | Test Error: 0.2011\n",
            "Epoch: 387 | Train Loss: 0.02562 | Train Error: 0.00862 | Test Loss: 1.628 | Test Error: 0.1996\n",
            "Epoch: 388 | Train Loss: 0.0258 | Train Error: 0.00826 | Test Loss: 1.636 | Test Error: 0.2043\n",
            "Epoch: 389 | Train Loss: 0.02676 | Train Error: 0.0087 | Test Loss: 1.676 | Test Error: 0.212\n",
            "Epoch: 390 | Train Loss: 0.02267 | Train Error: 0.00794 | Test Loss: 1.674 | Test Error: 0.2007\n",
            "Epoch: 391 | Train Loss: 0.02668 | Train Error: 0.009 | Test Loss: 1.73 | Test Error: 0.2036\n",
            "Epoch: 392 | Train Loss: 0.02496 | Train Error: 0.00848 | Test Loss: 1.598 | Test Error: 0.2009\n",
            "Epoch: 393 | Train Loss: 0.02436 | Train Error: 0.0078 | Test Loss: 1.698 | Test Error: 0.2073\n",
            "Epoch: 394 | Train Loss: 0.02185 | Train Error: 0.0069 | Test Loss: 1.683 | Test Error: 0.2074\n",
            "Epoch: 395 | Train Loss: 0.02777 | Train Error: 0.00952 | Test Loss: 1.587 | Test Error: 0.2068\n",
            "Epoch: 396 | Train Loss: 0.01984 | Train Error: 0.00684 | Test Loss: 1.722 | Test Error: 0.2263\n",
            "Epoch: 397 | Train Loss: 0.02566 | Train Error: 0.00868 | Test Loss: 1.831 | Test Error: 0.2249\n",
            "Epoch: 398 | Train Loss: 0.02799 | Train Error: 0.00898 | Test Loss: 1.664 | Test Error: 0.2191\n",
            "Epoch: 399 | Train Loss: 0.02445 | Train Error: 0.00808 | Test Loss: 1.767 | Test Error: 0.2247\n",
            "Epoch: 400 | Train Loss: 0.02646 | Train Error: 0.00838 | Test Loss: 1.761 | Test Error: 0.2224\n",
            "Epoch: 401 | Train Loss: 0.02163 | Train Error: 0.00702 | Test Loss: 1.665 | Test Error: 0.2001\n",
            "Epoch: 402 | Train Loss: 0.02178 | Train Error: 0.0069 | Test Loss: 1.67 | Test Error: 0.2128\n",
            "Epoch: 403 | Train Loss: 0.02677 | Train Error: 0.0082 | Test Loss: 1.647 | Test Error: 0.2046\n",
            "Epoch: 404 | Train Loss: 0.02361 | Train Error: 0.0075 | Test Loss: 1.693 | Test Error: 0.2209\n",
            "Epoch: 405 | Train Loss: 0.0235 | Train Error: 0.00756 | Test Loss: 1.624 | Test Error: 0.2004\n",
            "Epoch: 406 | Train Loss: 0.01995 | Train Error: 0.00678 | Test Loss: 1.73 | Test Error: 0.2114\n",
            "Epoch: 407 | Train Loss: 0.02439 | Train Error: 0.00782 | Test Loss: 1.692 | Test Error: 0.2171\n",
            "Epoch: 408 | Train Loss: 0.02299 | Train Error: 0.00724 | Test Loss: 1.723 | Test Error: 0.2131\n",
            "Epoch: 409 | Train Loss: 0.02617 | Train Error: 0.00908 | Test Loss: 1.641 | Test Error: 0.2163\n",
            "Epoch: 410 | Train Loss: 0.02107 | Train Error: 0.007 | Test Loss: 1.67 | Test Error: 0.2078\n",
            "Epoch: 411 | Train Loss: 0.02617 | Train Error: 0.00896 | Test Loss: 1.683 | Test Error: 0.2136\n",
            "Epoch: 412 | Train Loss: 0.02282 | Train Error: 0.00716 | Test Loss: 1.609 | Test Error: 0.207\n",
            "Epoch: 413 | Train Loss: 0.02569 | Train Error: 0.00828 | Test Loss: 1.765 | Test Error: 0.2245\n",
            "Epoch: 414 | Train Loss: 0.02281 | Train Error: 0.00792 | Test Loss: 1.728 | Test Error: 0.2213\n",
            "Epoch: 415 | Train Loss: 0.02423 | Train Error: 0.00824 | Test Loss: 1.675 | Test Error: 0.1991\n",
            "Epoch: 416 | Train Loss: 0.02585 | Train Error: 0.00816 | Test Loss: 1.628 | Test Error: 0.202\n",
            "Epoch: 417 | Train Loss: 0.02075 | Train Error: 0.00694 | Test Loss: 1.636 | Test Error: 0.196\n",
            "Epoch: 418 | Train Loss: 0.02439 | Train Error: 0.00818 | Test Loss: 1.644 | Test Error: 0.1957\n",
            "Epoch: 419 | Train Loss: 0.0217 | Train Error: 0.00702 | Test Loss: 1.781 | Test Error: 0.2272\n",
            "Epoch: 420 | Train Loss: 0.0222 | Train Error: 0.00728 | Test Loss: 1.753 | Test Error: 0.2192\n",
            "Epoch: 421 | Train Loss: 0.02292 | Train Error: 0.0077 | Test Loss: 1.722 | Test Error: 0.2174\n",
            "Epoch: 422 | Train Loss: 0.02457 | Train Error: 0.00778 | Test Loss: 1.706 | Test Error: 0.2128\n",
            "Epoch: 423 | Train Loss: 0.02162 | Train Error: 0.0074 | Test Loss: 1.667 | Test Error: 0.2121\n",
            "Epoch: 424 | Train Loss: 0.02103 | Train Error: 0.00676 | Test Loss: 1.696 | Test Error: 0.2083\n",
            "Epoch: 425 | Train Loss: 0.02189 | Train Error: 0.00722 | Test Loss: 1.775 | Test Error: 0.2195\n",
            "Epoch: 426 | Train Loss: 0.02537 | Train Error: 0.00808 | Test Loss: 1.715 | Test Error: 0.2087\n",
            "Epoch: 427 | Train Loss: 0.0235 | Train Error: 0.0079 | Test Loss: 1.724 | Test Error: 0.2211\n",
            "Epoch: 428 | Train Loss: 0.01879 | Train Error: 0.00592 | Test Loss: 1.697 | Test Error: 0.2016\n",
            "Epoch: 429 | Train Loss: 0.02308 | Train Error: 0.00782 | Test Loss: 1.764 | Test Error: 0.2129\n",
            "Epoch: 430 | Train Loss: 0.0236 | Train Error: 0.00804 | Test Loss: 1.794 | Test Error: 0.2284\n",
            "Epoch: 431 | Train Loss: 0.02555 | Train Error: 0.00836 | Test Loss: 1.751 | Test Error: 0.2167\n",
            "Epoch: 432 | Train Loss: 0.02164 | Train Error: 0.00704 | Test Loss: 1.718 | Test Error: 0.2125\n",
            "Epoch: 433 | Train Loss: 0.02282 | Train Error: 0.00782 | Test Loss: 1.71 | Test Error: 0.2173\n",
            "Epoch: 434 | Train Loss: 0.02168 | Train Error: 0.00662 | Test Loss: 1.69 | Test Error: 0.2035\n",
            "Epoch: 435 | Train Loss: 0.02066 | Train Error: 0.00688 | Test Loss: 1.715 | Test Error: 0.2151\n",
            "Epoch: 436 | Train Loss: 0.02038 | Train Error: 0.00658 | Test Loss: 1.734 | Test Error: 0.216\n",
            "Epoch: 437 | Train Loss: 0.02447 | Train Error: 0.0077 | Test Loss: 1.682 | Test Error: 0.2096\n",
            "Epoch: 438 | Train Loss: 0.02079 | Train Error: 0.00674 | Test Loss: 1.703 | Test Error: 0.2093\n",
            "Epoch: 439 | Train Loss: 0.0223 | Train Error: 0.0075 | Test Loss: 1.692 | Test Error: 0.2061\n",
            "Epoch: 440 | Train Loss: 0.02225 | Train Error: 0.00712 | Test Loss: 1.735 | Test Error: 0.2123\n",
            "Epoch: 441 | Train Loss: 0.02281 | Train Error: 0.0069 | Test Loss: 1.699 | Test Error: 0.2103\n",
            "Epoch: 442 | Train Loss: 0.02118 | Train Error: 0.00652 | Test Loss: 1.657 | Test Error: 0.2029\n",
            "Epoch: 443 | Train Loss: 0.02051 | Train Error: 0.00676 | Test Loss: 1.714 | Test Error: 0.2101\n",
            "Epoch: 444 | Train Loss: 0.02518 | Train Error: 0.0079 | Test Loss: 1.729 | Test Error: 0.2127\n",
            "Epoch: 445 | Train Loss: 0.0234 | Train Error: 0.00736 | Test Loss: 1.713 | Test Error: 0.2214\n",
            "Epoch: 446 | Train Loss: 0.01895 | Train Error: 0.0065 | Test Loss: 1.667 | Test Error: 0.2072\n",
            "Epoch: 447 | Train Loss: 0.02058 | Train Error: 0.00666 | Test Loss: 1.731 | Test Error: 0.2198\n",
            "Epoch: 448 | Train Loss: 0.02605 | Train Error: 0.00814 | Test Loss: 1.677 | Test Error: 0.2245\n",
            "Epoch: 449 | Train Loss: 0.02235 | Train Error: 0.00726 | Test Loss: 1.684 | Test Error: 0.209\n",
            "Epoch: 450 | Train Loss: 0.0205 | Train Error: 0.00704 | Test Loss: 1.729 | Test Error: 0.214\n",
            "Epoch: 451 | Train Loss: 0.02687 | Train Error: 0.00906 | Test Loss: 1.63 | Test Error: 0.2036\n",
            "Epoch: 452 | Train Loss: 0.01861 | Train Error: 0.0061 | Test Loss: 1.608 | Test Error: 0.2028\n",
            "Epoch: 453 | Train Loss: 0.01952 | Train Error: 0.0069 | Test Loss: 1.709 | Test Error: 0.218\n",
            "Epoch: 454 | Train Loss: 0.01739 | Train Error: 0.00576 | Test Loss: 1.697 | Test Error: 0.2049\n",
            "Epoch: 455 | Train Loss: 0.02192 | Train Error: 0.00728 | Test Loss: 1.673 | Test Error: 0.2051\n",
            "Epoch: 456 | Train Loss: 0.02334 | Train Error: 0.0076 | Test Loss: 1.638 | Test Error: 0.2103\n",
            "Epoch: 457 | Train Loss: 0.01955 | Train Error: 0.00624 | Test Loss: 1.733 | Test Error: 0.2222\n",
            "Epoch: 458 | Train Loss: 0.02048 | Train Error: 0.0066 | Test Loss: 1.639 | Test Error: 0.2035\n",
            "Epoch: 459 | Train Loss: 0.02256 | Train Error: 0.00746 | Test Loss: 1.596 | Test Error: 0.197\n",
            "Epoch: 460 | Train Loss: 0.02293 | Train Error: 0.00726 | Test Loss: 1.66 | Test Error: 0.213\n",
            "Epoch: 461 | Train Loss: 0.02165 | Train Error: 0.00706 | Test Loss: 1.64 | Test Error: 0.2055\n",
            "Epoch: 462 | Train Loss: 0.01925 | Train Error: 0.00638 | Test Loss: 1.668 | Test Error: 0.2019\n",
            "Epoch: 463 | Train Loss: 0.0226 | Train Error: 0.00724 | Test Loss: 1.634 | Test Error: 0.2056\n",
            "Epoch: 464 | Train Loss: 0.01869 | Train Error: 0.00618 | Test Loss: 1.644 | Test Error: 0.2065\n",
            "Epoch: 465 | Train Loss: 0.01707 | Train Error: 0.00562 | Test Loss: 1.692 | Test Error: 0.215\n",
            "Epoch: 466 | Train Loss: 0.02044 | Train Error: 0.00636 | Test Loss: 1.651 | Test Error: 0.2034\n",
            "Epoch: 467 | Train Loss: 0.02311 | Train Error: 0.0074 | Test Loss: 1.652 | Test Error: 0.1922\n",
            "Epoch: 468 | Train Loss: 0.02258 | Train Error: 0.00726 | Test Loss: 1.638 | Test Error: 0.1967\n",
            "Epoch: 469 | Train Loss: 0.01647 | Train Error: 0.0054 | Test Loss: 1.67 | Test Error: 0.2137\n",
            "Epoch: 470 | Train Loss: 0.01751 | Train Error: 0.00598 | Test Loss: 1.699 | Test Error: 0.2012\n",
            "Epoch: 471 | Train Loss: 0.01939 | Train Error: 0.0066 | Test Loss: 1.675 | Test Error: 0.2055\n",
            "Epoch: 472 | Train Loss: 0.01779 | Train Error: 0.0058 | Test Loss: 1.805 | Test Error: 0.2269\n",
            "Epoch: 473 | Train Loss: 0.02626 | Train Error: 0.00844 | Test Loss: 1.625 | Test Error: 0.2168\n",
            "Epoch: 474 | Train Loss: 0.02175 | Train Error: 0.0066 | Test Loss: 1.651 | Test Error: 0.1982\n",
            "Epoch: 475 | Train Loss: 0.01817 | Train Error: 0.00612 | Test Loss: 1.68 | Test Error: 0.2083\n",
            "Epoch: 476 | Train Loss: 0.01903 | Train Error: 0.0064 | Test Loss: 1.673 | Test Error: 0.2072\n",
            "Epoch: 477 | Train Loss: 0.01856 | Train Error: 0.0059 | Test Loss: 1.705 | Test Error: 0.2035\n",
            "Epoch: 478 | Train Loss: 0.02207 | Train Error: 0.00746 | Test Loss: 1.669 | Test Error: 0.2088\n",
            "Epoch: 479 | Train Loss: 0.01599 | Train Error: 0.0054 | Test Loss: 1.733 | Test Error: 0.213\n",
            "Epoch: 480 | Train Loss: 0.02207 | Train Error: 0.00702 | Test Loss: 1.6 | Test Error: 0.1931\n",
            "Epoch: 481 | Train Loss: 0.0167 | Train Error: 0.00524 | Test Loss: 1.715 | Test Error: 0.208\n",
            "Epoch: 482 | Train Loss: 0.02045 | Train Error: 0.0066 | Test Loss: 1.801 | Test Error: 0.2104\n",
            "Epoch: 483 | Train Loss: 0.02025 | Train Error: 0.00652 | Test Loss: 1.72 | Test Error: 0.2001\n",
            "Epoch: 484 | Train Loss: 0.02203 | Train Error: 0.00718 | Test Loss: 1.745 | Test Error: 0.2109\n",
            "Epoch: 485 | Train Loss: 0.02022 | Train Error: 0.00668 | Test Loss: 1.712 | Test Error: 0.2052\n",
            "Epoch: 486 | Train Loss: 0.01832 | Train Error: 0.00576 | Test Loss: 1.722 | Test Error: 0.204\n",
            "Epoch: 487 | Train Loss: 0.02104 | Train Error: 0.00696 | Test Loss: 1.786 | Test Error: 0.209\n",
            "Epoch: 488 | Train Loss: 0.01764 | Train Error: 0.00596 | Test Loss: 1.689 | Test Error: 0.2043\n",
            "Epoch: 489 | Train Loss: 0.02245 | Train Error: 0.00744 | Test Loss: 1.667 | Test Error: 0.2048\n",
            "Epoch: 490 | Train Loss: 0.01898 | Train Error: 0.00682 | Test Loss: 1.748 | Test Error: 0.2062\n",
            "Epoch: 491 | Train Loss: 0.01709 | Train Error: 0.00548 | Test Loss: 1.662 | Test Error: 0.2043\n",
            "Epoch: 492 | Train Loss: 0.01816 | Train Error: 0.00558 | Test Loss: 1.819 | Test Error: 0.2204\n",
            "Epoch: 493 | Train Loss: 0.02255 | Train Error: 0.00716 | Test Loss: 1.741 | Test Error: 0.2191\n",
            "Epoch: 494 | Train Loss: 0.01953 | Train Error: 0.0066 | Test Loss: 1.685 | Test Error: 0.2058\n",
            "Epoch: 495 | Train Loss: 0.01424 | Train Error: 0.00508 | Test Loss: 1.653 | Test Error: 0.2024\n",
            "Epoch: 496 | Train Loss: 0.01855 | Train Error: 0.00596 | Test Loss: 1.697 | Test Error: 0.2024\n",
            "Epoch: 497 | Train Loss: 0.02287 | Train Error: 0.0074 | Test Loss: 1.702 | Test Error: 0.2132\n",
            "Epoch: 498 | Train Loss: 0.01773 | Train Error: 0.00608 | Test Loss: 1.671 | Test Error: 0.2013\n",
            "Epoch: 499 | Train Loss: 0.01584 | Train Error: 0.0055 | Test Loss: 1.754 | Test Error: 0.2067\n",
            "Epoch: 500 | Train Loss: 0.0213 | Train Error: 0.00704 | Test Loss: 1.739 | Test Error: 0.2107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FntSGMUksQJx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}